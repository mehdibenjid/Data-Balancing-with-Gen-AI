{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rg59XDzGlmNx",
    "outputId": "298c1fa1-fdd4-4a0c-e3cf-fde4bc95ffc2"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Importing neural network modules\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, BatchNormalization, LeakyReLU, Dropout\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.initializers import RandomNormal\n",
    "# Importing some machine learning modules\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "# Import data visualization modules\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QulLdZ53nqBF"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F61uPjLozPzn"
   },
   "source": [
    "Check the data shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ie9B694UlDok"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "782ekqkDsAZ8"
   },
   "source": [
    "Let's see how many genuine and limited fraudulent records we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owr545uamDd_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p30Sel1l0zHe"
   },
   "source": [
    "### Task 2 - Data Preprocessing and Exploration\n",
    "\n",
    "*   Removing all the rows with `Nan` values\n",
    "*   Removing `Time` column\n",
    "*   Feature Scaling `Amount` column\n",
    "*   Split the data into features and labels\n",
    "*   Data Exploration\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LyrwqwZWzclz"
   },
   "source": [
    "Removing the rows `Nan` values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8oQ7BUhtzhJf"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O3qtMCEcil5E"
   },
   "source": [
    "Removing Time column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0tBZhNbvinPu"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hEChnc_GiAkd"
   },
   "source": [
    "Feature Scaling of Amount column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "nykH6OHOiHZx"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvxgYLZJ0Fgg"
   },
   "source": [
    "Let's split the genuine and fraud records into separate dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KosQdd1yys4N"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AweLq-TNbyyy"
   },
   "source": [
    "Split the data into features and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "IuNEggqWcY3S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_uWA4S5HhY02"
   },
   "source": [
    "Data Exploration\n",
    "  - Apply PCA to reduce the dimensionality of features `X` into two dimensions\n",
    "  - Use a scatter plot to visualize our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oc4JvsU9UaQH"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fkrSGlnZVmdc"
   },
   "source": [
    "Let's Use a scatter plot to visualize our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KAJ9F9LIVjs_"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tgFgpoOAS-8I"
   },
   "source": [
    "### Task 3 - Building the Generator Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-GS_SZ2gZKzd"
   },
   "source": [
    "Write a method to create the Generator model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "56eOgnOdTA9n"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ypwr3yYYaSq5"
   },
   "source": [
    "### Task 4 - Building the Discriminator Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-78WbhfmaZ8t"
   },
   "source": [
    "Write a method to create the Discriminator model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SfxnnV3uagl1"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IYIW2eB6bWg6"
   },
   "source": [
    "### Task 5 - Combine Generator and Discriminator models to Build The GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vt2h8iDxzEp6"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KZCGFIKuzXxe"
   },
   "source": [
    "Let's create a method that generates synthetic data using the Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oPHMbppazcvb"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qXNZbInhmW5i"
   },
   "source": [
    "### Task 6 - Train and evaluate our GAN\n",
    "*    Defining some variables\n",
    "*    Creating our GAN\n",
    "*    Training the GAN\n",
    "*    Monitor the GAN performance using PCA\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7Vf9ZCE545g"
   },
   "outputs": [],
   "source": [
    "def monitor_generator(generator):\n",
    "    # Initialize a PCA (Principal Component Analysis) object with 2 components\n",
    "    pca = PCA(n_components=2)\n",
    "\n",
    "    # Drop the 'Class' column from the fraud dataset to get real data\n",
    "    real_fraud_data = data_fraud.drop(\"Class\", axis=1)\n",
    "\n",
    "    # Transform the real fraud data using PCA\n",
    "    transformed_data_real = pca.fit_transform(real_fraud_data.values)\n",
    "\n",
    "    # Create a DataFrame for the transformed real data and add a 'label' column with the value 'real'\n",
    "    df_real = pd.DataFrame(transformed_data_real)\n",
    "    df_real['label'] = \"real\"\n",
    "\n",
    "    # Generate synthetic fraud data using the provided generator and specify the number of samples (492 in this case)\n",
    "    synthetic_fraud_data = generate_synthetic_data(generator, 492)\n",
    "\n",
    "    # Transform the synthetic fraud data using PCA\n",
    "    transformed_data_fake = pca.fit_transform(synthetic_fraud_data)\n",
    "\n",
    "    # Create a DataFrame for the transformed fake data and add a 'label' column with the value 'fake'\n",
    "    df_fake = pd.DataFrame(transformed_data_fake)\n",
    "    df_fake['label'] = \"fake\"\n",
    "\n",
    "    # Concatenate the real and fake data DataFrames\n",
    "    df_combined = pd.concat([df_real, df_fake])\n",
    "\n",
    "    # Create a scatterplot to visualize the data points, using the first and second PCA components as x and y, respectively,\n",
    "    # and color points based on the 'label' column, with a size of 10\n",
    "    plt.figure()\n",
    "    sns.scatterplot(data=df_combined, x=0, y=1, hue='label', s=10)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Grtte84z-NiK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OCHApltUa3Yh"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WlGLX4Uk6l2C"
   },
   "source": [
    "### Task 7 - Generate synthetic data using the trained Generator\n",
    "\n",
    "*   Generate 1000 fradulent data points using the trained generator\n",
    "*   Compare the distribution of `real` and `synthetic` fradulent data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BA1OkRU5UHOw"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vRp9QVL2VzrF"
   },
   "source": [
    "Checking the individual feature distribution of `synthetic` and `real` fraud data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 227
    },
    "id": "VjR196XqKfVd",
    "outputId": "1414506b-7621-45c6-edbb-30f98af536f9"
   },
   "outputs": [],
   "source": [
    "for col in combined_df.columns:\n",
    "  plt.figure()\n",
    "  fig = px.histogram(combined_df, color = 'label', x=col,barmode=\"overlay\", title = f'Feature {col}', width = 640, height = 500)\n",
    "  fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "pzZuOOGPHvZu"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
